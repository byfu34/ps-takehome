This program develops a K-Nearest Neighbors model to classify flower type from petal length and petal width. First run main.py to initialize the model, then run api.py to create the web API and load the model. The web API serves at the localhost, and the URL takes query inputs petal_width and petal_length to feed as features to the model. Go to localhost:5000/?petal_width=___&petal_length=___ in a web browser and fill in the blanks with the features for a prediction. For example, to predict the type of flower with a petal width of 3 cm and a petal length of 1 cm, the URL will be localhost:5000/?petal_width=3&petal_length=1. You will see a webpage with the prediction, 0, 1, or 2, at the top of the page.

## Question Answers

1.	For very large datasets, I would want to transition the model to a Bayesian Network. The network enables the data to be factorized into smaller local distributions. This way, the model requires less training data and can be retrained with only new data rather than retraining with the entire dataset again. A Bayesian Network also works for simple datasets like the Iris dataset, so if size increased but complexity remained low, it would remain viable. 

2.	My optimal versioning strategy would use Git to house code for the API and would include version numbers in the URL to distinguish between major updates to the model and/or its training. The pros of this strategy are many. For one, accessing different versions through the URL is easy and straightforward. For the developers, using Git for versioning enables consistent commits with narrations about the changes, and allow an entire team to view all the code and the changes made at certain times. Within the Git repository, a log file would exist where team members keep track of times when the model has undergone major changes or been retrained. Before doing so, however, a strategy would be to copy the project to a new folder so that it could be maintained as an earlier version. This way, API users would have the option to use earlier versions based on the URL, and the history of the project is recorded in detail for the team. The cons of this strategy include some lack of automation with needing to save earlier project versions and update URLs. More importantly, Git can struggle to handle large datasets, and even the extension Git Large File Storage limits files to 2 GB in size. In that case, version control might become more complex with frequently updated large datasets needing to be handled outside Git. 

3.	My choice of model was a K-Nearest Neighbors model. After visualizing the dataset and noting its simplicity, and because this was a classification problem, immediately my first two choices were a K-Nearest Neighbors or a Naïve Bayes model. After testing both, the K-Nearest Neighbors model with a hyperparameter of 1 neighbor performed best. K-Nearest Neighbors fits the model due to its simplicity, and specifically the clear dependence of the flower type on petal length and petal width. Thus, overtraining with a more complex model only makes it less accurate. The benefits of K-Nearest Neighbors are seen in straightforward datasets. Without outliers and with features grouped tightly for different types, it works very well. However, as the dataset grows in size or complexity, the model may struggle because it is unable to capture the new shape, and is reliant on the rigid, organized structure of a small, simple dataset. For a larger, more complex system, I would use a Naïve Bayesian model, likely a Gaussian model, or if the dataset is large enough a Bayesian Network. These Bayesian models still maintain a high accuracy for small, simple datasets, but also scale with size and complexity.
